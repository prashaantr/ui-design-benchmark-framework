[
  {
    "id": "perrig-2024-ux-measurements",
    "title": "Measurement practices in user experience (UX) research: a systematic quantitative literature review",
    "authors": "Sebastian A. C. Perrig, Lena Fanya Aeschbach, Nicolas Scharowski, Nick von Felten, Klaus Opwis, Florian Brühlmann",
    "journal": "Frontiers in Computer Science",
    "conference": "",
    "year": "2024",
    "url": "https://www.frontiersin.org/journals/computer-science/articles/10.3389/fcomp.2024.1368860/full",
    "hypotheses": "Current UX research lacks consistency in measurement practices, with widespread improper use of survey scales",
    "notes": "Systematic review of 153 papers from ACM CHI 2019-2022. Identified 85 different scales and 172 constructs. Most scales used only once (70.59%), highlighting lack of standardization in UX measurement practices.",
    "strengths": "Comprehensive systematic methodology, large dataset, quantitative analysis of measurement practices, identification of methodological gaps",
    "weaknesses": "Limited to CHI proceedings, focus only on survey scales, doesn't address solutions for identified problems",
    "citation": "Perrig, S. A. C., et al. (2024). Measurement practices in user experience (UX) research: a systematic quantitative literature review. Frontiers in Computer Science, 6, 1368860.",
    "_isExample": false
  },
  {
    "id": "nielsen-1990-heuristic-evaluation",
    "title": "Heuristic evaluation of user interfaces",
    "authors": "Jakob Nielsen, Rolf Molich",
    "journal": "",
    "conference": "SIGCHI Conference on Human Factors in Computing Systems",
    "year": "1990",
    "url": "https://www.nngroup.com/articles/ten-usability-heuristics/",
    "hypotheses": "Expert evaluators can identify usability problems systematically using general heuristic principles without extensive user testing",
    "notes": "Foundational work establishing the 10 usability heuristics that became the gold standard for expert-based UI evaluation. Introduced systematic methodology for identifying usability problems through expert inspection.",
    "strengths": "Established fundamental principles, widely adopted methodology, cost-effective evaluation approach, systematic framework",
    "weaknesses": "Evaluator expertise dependent, may miss user-specific issues, limited validation of completeness",
    "citation": "Nielsen, J., & Molich, R. (1990). Heuristic evaluation of user interfaces. Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, 249-256.",
    "_isExample": false
  },
  {
    "id": "shneiderman-1985-golden-rules",
    "title": "Designing the User Interface: Strategies for Effective Human-Computer Interaction",
    "authors": "Ben Shneiderman",
    "journal": "",
    "conference": "",
    "year": "1985",
    "url": "https://www.interaction-design.org/literature/article/shneiderman-s-eight-golden-rules-will-help-you-design-better-interfaces",
    "hypotheses": "User interface design can be guided by universal principles that optimize human-computer interaction across different systems and contexts",
    "notes": "Introduced the Eight Golden Rules of Interface Design: consistency, shortcuts for frequent users, informative feedback, closure, error handling, reversibility, user control, and reduced memory load. These principles remain fundamental to UI design practice.",
    "strengths": "Timeless principles, broad applicability, clear guidelines for designers, empirically validated through widespread adoption",
    "weaknesses": "High-level guidance may need domain-specific interpretation, limited quantitative validation methods",
    "citation": "Shneiderman, B. (1985). Designing the User Interface: Strategies for Effective Human-Computer Interaction. Addison-Wesley.",
    "_isExample": false
  },
  {
    "id": "hercegfi-2024-team-usability",
    "title": "Team usability testing: development and validation of a groupware usability evaluation method",
    "authors": "Károly Hercegfi",
    "journal": "Cognition, Technology & Work",
    "conference": "",
    "year": "2024",
    "url": "https://link.springer.com/article/10.1007/s10111-024-00759-5",
    "hypotheses": "Team-level usability problems in collaborative software cannot be identified through individual user testing and require specialized group evaluation methods",
    "notes": "Developed and validated Team Usability Testing method for synchronous collaborative software. Combines questionnaires, screen recording, and group interviews based on collaboration mechanics theory. Addresses limitations of single-user evaluation methods.",
    "strengths": "Novel methodology for collaborative software, empirical validation, addresses gap in evaluation methods, practical framework",
    "weaknesses": "Limited to synchronous collaborative software, requires specialized expertise, resource intensive",
    "citation": "Hercegfi, K. (2024). Team usability testing: development and validation of a groupware usability evaluation method. Cognition, Technology & Work, 26, 487-506.",
    "_isExample": false
  },
  {
    "id": "gonzalez-2013-balores",
    "title": "BaLOReS: A Framework for Quantitative User Interface Evaluation",
    "authors": "Salvador González López, Francisco Montero Simarro, Pascual González López",
    "journal": "",
    "conference": "New Trends in Interaction, Virtual Reality and Modeling",
    "year": "2013",
    "url": "https://link.springer.com/chapter/10.1007/978-1-4471-5445-7_10",
    "hypotheses": "UI aesthetic quality can be objectively measured through structural principles and automated metrics, improving design satisfaction",
    "notes": "Presents five structural principles (Balance, Layout, Order, Rhythm, Simplicity) with accompanying aesthetic metrics. Includes BGLayout tool for automated calculation. Demonstrates objective measurement of UI aesthetic quality.",
    "strengths": "Objective measurement approach, automated tool implementation, comprehensive case study validation, practical applicability",
    "weaknesses": "Focus primarily on visual aesthetics, limited validation across diverse UI types, requires specific tool adoption",
    "citation": "González López, S., Montero Simarro, F., & González López, P. (2013). BaLOReS: A Framework for Quantitative User Interface Evaluation. In New Trends in Interaction, Virtual Reality and Modeling (pp. 127-143). Springer.",
    "_isExample": false
  },
  {
    "id": "rohrer-2017-pure-method",
    "title": "Quantifying and Comparing Ease of Use Without Breaking the Bank",
    "authors": "Christian Rohrer",
    "journal": "",
    "conference": "",
    "year": "2017",
    "url": "https://www.nngroup.com/articles/pure-method/",
    "hypotheses": "Usability can be quantified cost-effectively through focused measurement of user friction, providing both metrics and actionable insights",
    "notes": "Introduces PURE method for measuring interface friction. Provides quantitative metrics while remaining cost-effective. Demonstrates how lightweight evaluation can yield both quantitative and qualitative insights for improvement.",
    "strengths": "Cost-effective approach, combines quantitative and qualitative insights, practical business application, validated methodology",
    "weaknesses": "Limited scope to friction measurement, requires training for proper application, may not capture all usability aspects",
    "citation": "Rohrer, C. (2017). Quantifying and comparing ease of use without breaking the bank. Nielsen Norman Group.",
    "_isExample": false
  },
  {
    "id": "borsci-2013-five-user",
    "title": "Reviewing and extending the five-user assumption: a grounded procedure for interaction evaluation",
    "authors": "Simone Borsci, Robert D. Macredie, Julie Barnett, Jennifer Martin, Jasna Kuljis, Terry Young",
    "journal": "ACM Transactions on Computer-Human Interaction (TOCHI)",
    "conference": "",
    "year": "2013",
    "url": "https://eprints.nottingham.ac.uk/29453",
    "hypotheses": "The five-user assumption for usability testing lacks proper statistical foundation and context-specific validation",
    "notes": "Comprehensive analysis challenging Nielsen's five-user assumption. Proposes grounded procedure considering evaluation context and goals. Demonstrates importance of statistical rigor in determining adequate sample sizes.",
    "strengths": "Rigorous statistical analysis, addresses fundamental assumption, provides alternative methodology, strong theoretical foundation",
    "weaknesses": "Complex methodology may be difficult to implement, challenges widely accepted practice, requires statistical expertise",
    "citation": "Borsci, S., et al. (2013). Reviewing and extending the five-user assumption: a grounded procedure for interaction evaluation. ACM Transactions on Computer-Human Interaction (TOCHI), 20(5), 29/1-29/23.",
    "_isExample": false
  },
  {
    "id": "diaz-2019-standardized-questionnaires",
    "title": "Standardized Questionnaires for User Experience Evaluation: A Systematic Literature Review",
    "authors": "Ignacio Díaz Oreiro, Gustavo López Herrera, Luis Quesada Quirós, Luis Alberto Guerrero Blanco",
    "journal": "Proceedings",
    "conference": "",
    "year": "2019",
    "url": "https://www.kerwa.ucr.ac.cr/items/7f97d126-1f05-4aaa-994f-cad040801b2e",
    "hypotheses": "AttrakDiff, UEQ, and meCUE represent the most recognized standardized questionnaires for UX evaluation, with systematic patterns in their usage",
    "notes": "Systematic literature review of 946 papers from four databases, analyzing 553 primary studies. Categorizes usage patterns of standardized UX questionnaires, revealing geographical and contextual variations in application.",
    "strengths": "Comprehensive database search, large sample size, systematic categorization, practical insights for researchers",
    "weaknesses": "Limited to three specific questionnaires, temporal scope limitations, descriptive rather than evaluative analysis",
    "citation": "Díaz Oreiro, I., et al. (2019). Standardized questionnaires for user experience evaluation: A systematic literature review. Proceedings, 31(1), 14.",
    "_isExample": false
  },
  {
    "id": "hinderks-2017-ueq-benchmark",
    "title": "Construction of a Benchmark for the User Experience Questionnaire (UEQ)",
    "authors": "Andreas Hinderks, Jörg Thomaschewski",
    "journal": "International Journal of Interactive Multimedia and Artificial Intelligence",
    "conference": "",
    "year": "2017",
    "url": "https://www.academia.edu/30701195/Construction_of_a_Benchmark_for_the_User_Experience_Questionnaire_UEQ",
    "hypotheses": "UX measurement results can be meaningfully interpreted through benchmarking against established standards rather than absolute scores",
    "notes": "Constructs benchmarks for the User Experience Questionnaire (UEQ) based on large dataset analysis. Provides contextual standards for meaningful interpretation of UX measurement results across different systems and domains.",
    "strengths": "Large dataset foundation, practical interpretation framework, enables comparative analysis, standardized benchmarks",
    "weaknesses": "Limited to UEQ instrument, benchmark validity depends on dataset representativeness, cultural/contextual limitations",
    "citation": "Hinderks, A., & Thomaschewski, J. (2017). Construction of a benchmark for the User Experience Questionnaire (UEQ). International Journal of Interactive Multimedia and Artificial Intelligence, 4(4), 40-44.",
    "_isExample": false
  },
  {
    "id": "carter-2015-iso-9241-11",
    "title": "ISO 9241-11 Revised: What Have We Learnt About Usability Since 1998?",
    "authors": "Jim Carter",
    "journal": "",
    "conference": "Human-Computer Interaction: Design and Evaluation",
    "year": "2015",
    "url": "https://www.academia.edu/78497303/ISO_9241_11_Revised_What_Have_We_Learnt_About_Usability_Since_1998",
    "hypotheses": "The ISO 9241-11 usability definition requires updating to reflect contemporary understanding of user experience and context-dependent usability",
    "notes": "Analysis of ISO 9241-11 revision process, examining evolution of usability understanding since 1998. Documents integration of contemporary UX research into international standards framework.",
    "strengths": "Standards perspective, historical analysis, identifies evolution in usability understanding, practical implications for standardization",
    "weaknesses": "Limited scope to single standard, descriptive rather than empirical analysis, implementation challenges not addressed",
    "citation": "Carter, J. (2015). ISO 9241-11 revised: What have we learnt about usability since 1998? In Human-Computer Interaction: Design and Evaluation (pp. 143-151). Springer.",
    "_isExample": false
  },
  {
    "id": "lauesen-2005-heuristic-vs-testing",
    "title": "Heuristic Evaluation of User Interfaces versus Usability Testing",
    "authors": "Soren Lauesen, Mimi Pave Musgrove",
    "journal": "",
    "conference": "",
    "year": "2005",
    "url": "https://www.itu.dk/~slauesen/Papers/Chapter14_with_intro.pdf",
    "hypotheses": "Heuristic evaluation and usability testing have different strengths and limitations, with effectiveness depending more on evaluator expertise than method choice",
    "notes": "Statistical comparison of 17 evaluation teams assessing the same interface: 8 using heuristic evaluation, 9 using usability testing. Found no significant difference between methods, highlighting importance of evaluator expertise over technique selection.",
    "strengths": "Rigorous statistical comparison, large evaluator sample, practical insights, addresses fundamental methodological question",
    "weaknesses": "Single interface tested, limited generalizability, evaluator selection effects, temporal constraints",
    "citation": "Lauesen, S., & Musgrove, M. P. (2005). Heuristic evaluation of user interfaces versus usability testing. In User Interface Design - A Software Engineering Perspective (Chapter 14). Addison-Wesley.",
    "_isExample": false
  },
  {
    "id": "bailey-1992-usability-testing-vs-heuristic",
    "title": "Usability Testing vs. Heuristic Evaluation: A Head-to-Head Comparison",
    "authors": "Robert W Bailey, Robert W Allan, P Raiello",
    "journal": "Proceedings of the Human Factors and Ergonomics Society Annual Meeting",
    "conference": "Human Factors and Ergonomics Society Annual Meeting",
    "year": "1992",
    "url": "https://journals.sagepub.com/doi/10.1177/154193129203600431",
    "hypotheses": "Usability testing and heuristic evaluation identify different types of problems, suggesting complementary rather than competing approaches",
    "notes": "Early comparative study of evaluation methods, demonstrating that different approaches can miss different types of problems. Provides foundational evidence for multi-method evaluation strategies.",
    "strengths": "Pioneering comparative research, practical insights for method selection, demonstrates complementary nature of methods",
    "weaknesses": "Limited sample size, dated technology context, methodological limitations by contemporary standards",
    "citation": "Bailey, R. W., Allan, R. W., & Raiello, P. (1992). Usability testing vs. heuristic evaluation: A head-to-head comparison. Proceedings of the Human Factors and Ergonomics Society Annual Meeting.",
    "_isExample": false
  },
  {
    "id": "assila-2016-standardized-questionnaires",
    "title": "Standardized Usability Questionnaires: Features and Quality Focus",
    "authors": "Ahlem Assila, Káthia Marçal de Oliveira, Houcine Ezzedine",
    "journal": "Electronic Journal of Computer Science and Information Technology",
    "conference": "",
    "year": "2016",
    "url": "https://hal.science/hal-03400437/",
    "hypotheses": "Standardized usability questionnaires vary significantly in features and quality focus, requiring systematic comparison for appropriate selection",
    "notes": "Comprehensive analysis of standardized usability questionnaires, examining features, quality focus, and comparative characteristics. Provides framework for selecting appropriate instruments based on evaluation goals.",
    "strengths": "Comprehensive instrument comparison, systematic analysis framework, practical selection guidance, quality assessment",
    "weaknesses": "Limited to questionnaire instruments, static analysis without empirical validation, temporal scope limitations",
    "citation": "Assila, A., Marçal de Oliveira, K., & Ezzedine, H. (2016). Standardized usability questionnaires: Features and quality focus. Electronic Journal of Computer Science and Information Technology.",
    "_isExample": false
  },
  {
    "id": "pribeanu-2017-revised-heuristics",
    "title": "A Revised Set of Usability Heuristics for the Evaluation of Interactive Systems",
    "authors": "Costin Pribeanu",
    "journal": "Informatica Economică",
    "conference": "",
    "year": "2017",
    "url": "https://revistaie.ase.ro/content/83/03%20-%20pribeanu.pdf",
    "hypotheses": "Existing usability heuristics can be refined and reorganized into clearer hierarchical structure for more effective evaluation",
    "notes": "Proposes revised set of 14 usability heuristics organized into four groups: user guidance, user effort, user control and freedom, and user support. Based on experience with e-government website evaluation.",
    "strengths": "Clear hierarchical organization, reduced number of heuristics, practical validation through application, improved clarity",
    "weaknesses": "Limited validation beyond e-government domain, subjective refinement process, may not capture all usability aspects",
    "citation": "Pribeanu, C. (2017). A revised set of usability heuristics for the evaluation of interactive systems. Informatica Economică, 21(3), 31-42.",
    "_isExample": false
  },
  {
    "id": "ahiaklo-kuz-2025-r-verdict",
    "title": "Usability Assessment of the R-Verdict Schema: A New Paradigm for Usage-Centric Design and Evaluation",
    "authors": "Noble Ametame Yao Ahiaklo-Kuz",
    "journal": "Global Journal of Researches in Engineering",
    "conference": "",
    "year": "2025",
    "url": "https://globaljournals.org/GJRE_Volume25/2-Usability-Assessment.pdf",
    "hypotheses": "The R-Verdict Schema based on Relevance and Relation principles provides effective guidance for novice designers in UI development",
    "notes": "Investigates how novice designers apply the R-Verdict Schema in real design tasks. Evaluates effectiveness in enhancing usability, consistency, and decision-making through controlled experiments and qualitative feedback.",
    "strengths": "Focus on novice designer needs, controlled experimental design, practical application validation, educational implications",
    "weaknesses": "Limited to novice designers, single schema evaluation, generalizability questions, limited comparative analysis",
    "citation": "Ahiaklo-Kuz, N. A. Y. (2025). Usability assessment of the R-Verdict schema: A new paradigm for usage-centric design and evaluation. Global Journal of Researches in Engineering, 25(1).",
    "_isExample": false
  },
  {
    "id": "wang-2023-ux-calculator",
    "title": "UX Calculator: An Online Tool to Support User Testing",
    "authors": "Ruojun Wang, Shang-Lin Chen, Chantal Labbé, Marc Fredette, Amine Abdessemed, François Courtemanche, Constantinos K. Coursaris, Sylvain Sénécal, Pierre-Majorique Léger",
    "journal": "",
    "conference": "Design, User Experience, and Usability (HCII 2023)",
    "year": "2023",
    "url": "https://link.springer.com/chapter/10.1007/978-3-031-35702-2_7",
    "hypotheses": "UX data analysis can be made more accessible and cost-effective through lightweight web-based statistical tools for practitioners",
    "notes": "Presents design and development of UX Calculator (uxcalc.web.app), a web-based tool for statistical tests in UX assessment. Enables two-group comparisons without requiring statistical programming expertise.",
    "strengths": "Practical tool development, addresses accessibility barriers, cost-effective solution, practitioner-focused design",
    "weaknesses": "Limited statistical functionality, requires validation of tool accuracy, user training still needed, scope limitations",
    "citation": "Wang, R., et al. (2023). UX Calculator: An Online Tool to Support User Testing. In Design, User Experience, and Usability (HCII 2023) (pp. 101-111). Springer.",
    "_isExample": false
  },
  {
    "id": "duan-2023-semantic-grouping",
    "title": "Towards Semantically-Aware UI Design Tools: Design, Implementation and Evaluation of Semantic Grouping Guidelines",
    "authors": "Peitong Duan, Bjoern Hartmann, Karina Nguyen, Yang Li, Marti Hearst, Meredith Morris",
    "journal": "",
    "conference": "ICML Workshop",
    "year": "2023",
    "url": "https://people.eecs.berkeley.edu/~bjoern/papers/duan-semanticgrouping-icmlws2023.pdf",
    "hypotheses": "UI design tools can be enhanced through semantic grouping guidelines that capture how designers think about semantic structure",
    "notes": "Develops five semantic grouping guidelines for UI design tools based on empirical observations, literature review, and expert feedback. Demonstrates implementation through computational metrics that detect grouping violations.",
    "strengths": "Empirical guideline development, computational implementation, expert validation, practical tool integration potential",
    "weaknesses": "Limited scope to semantic grouping, requires tool integration, validation on limited UI dataset, implementation complexity",
    "citation": "Duan, P., et al. (2023). Towards semantically-aware UI design tools: Design, implementation and evaluation of semantic grouping guidelines. ICML Workshop.",
    "_isExample": false
  },
  {
    "id": "ramadhanti-2023-heuristic-review",
    "title": "The use of heuristic evaluation on UI/UX design: A review to anticipate web app's usability",
    "authors": "Natasya Titania Ramadhanti, Cucuk Wawan Budiyanto, Rosihan Ari Yuana",
    "journal": "American Institute of Physics Conference Series",
    "conference": "",
    "year": "2023",
    "url": "https://ui.adsabs.harvard.edu/abs/2023AIPC.2540h0008R/abstract",
    "hypotheses": "Heuristic evaluation significantly influences UI/UX quality, with design principles, user involvement, and evaluator perceptions as key success factors",
    "notes": "Review of 455 articles (1990-2020) on heuristic evaluation in UI/UX design. Identifies three competing factors influencing usability: design principles, user involvement, and evaluator perceptions. Systematic literature review methodology.",
    "strengths": "Comprehensive literature scope, systematic methodology, identifies key success factors, practical implications",
    "weaknesses": "Review-based rather than empirical, temporal limitations, limited novel methodological contributions",
    "citation": "Ramadhanti, N. T., Budiyanto, C. W., & Yuana, R. A. (2023). The use of heuristic evaluation on UI/UX design: A review to anticipate web app's usability. American Institute of Physics Conference Series, 2540, 080008.",
    "_isExample": false
  },
  {
    "id": "liu-2025-mobile-visualization",
    "title": "Mobile Data Visualisation Interface Design for Industrial Applications: User Experience Evaluation and Design Guidelines",
    "authors": "I-Chin Liu",
    "journal": "Applied Sciences",
    "conference": "",
    "year": "2025",
    "url": "https://www.mdpi.com/2076-3417/15/19/10832",
    "hypotheses": "Mobile data visualization interfaces require specialized design guidelines and evaluation methods for industrial applications",
    "notes": "Develops design guidelines and evaluation methods specifically for mobile data visualization interfaces in industrial contexts. Addresses unique challenges of mobile visualization and industrial requirements.",
    "strengths": "Domain-specific focus, practical design guidelines, addresses emerging technology needs, industrial application validation",
    "weaknesses": "Limited to mobile visualization domain, narrow application scope, limited comparative validation",
    "citation": "Liu, I-C. (2025). Mobile data visualisation interface design for industrial applications: User experience evaluation and design guidelines. Applied Sciences, 15(19), 10832.",
    "_isExample": false
  },
  {
    "id": "miki-2015-ux-evaluation-framework",
    "title": "User Experience Evaluation Framework for Human-Centered Design",
    "authors": "Hiroyuki Miki",
    "journal": "",
    "conference": "",
    "year": "2015",
    "url": "https://www.researchgate.net/publication/282361657_User_Experience_Evaluation_Framework_for_Human-Centered_Design",
    "hypotheses": "UX evaluation can be systematically integrated with human-centered design processes through unified framework combining usability and UX assessment",
    "notes": "Proposes integrated evaluation framework combining usability (ISO 9241-11) and UX assessment (ACSI-based). Addresses gap between UX definition in ISO 9241-210 and practical evaluation methods.",
    "strengths": "Framework integration approach, standards-based foundation, human-centered design alignment, systematic methodology",
    "weaknesses": "Limited empirical validation, framework complexity, implementation challenges, generalizability questions",
    "citation": "Miki, H. (2015). User experience evaluation framework for human-centered design. ResearchGate preprint.",
    "_isExample": false
  }
]